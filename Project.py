# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hDTO2LM3BfKSBf7xbDslE9i8NijB75Bl
"""

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import joblib

# Load the dataset
data = pd.read_csv('/content/Personalized_Workout_Plan_Dataset.csv')

# Display dataset structure
data.head()

# Check for missing values
if data.isnull().sum().sum() > 0:
    print("Missing values found! Filling with default values...")
    data = data.fillna(method='ffill')

# Encoding categorical variables
label_encoder = LabelEncoder()
for column in ['Gender', 'Goal', 'Fitness Level', 'Equipment', 'Exercises', 'Intensity', 'Frequency']:
    data[column] = label_encoder.fit_transform(data[column])

# Features (X) and Target (y)
X = data[['Age', 'Gender', 'Weight', 'Goal', 'Fitness Level', 'Duration', 'Equipment', 'Intensity']]
y = data['Exercises']  # Predicting 'Exercises'

# Standardize numerical features
scaler = StandardScaler()
X[['Age', 'Weight', 'Duration']] = scaler.fit_transform(X[['Age', 'Weight', 'Duration']])

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the model
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Evaluate the model
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# Save the model and scaler for Streamlit deployment
joblib.dump(model, 'workout_recommender_model.pkl')
joblib.dump(scaler, 'scaler.pkl')

print("Model and scaler saved successfully!")









# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import joblib

# Load the dataset
data = pd.read_csv('/content/Personalized_Workout_Plan_Dataset.csv')

# Display dataset structure
data.head()

# Check for missing values
if data.isnull().sum().sum() > 0:
    print("Missing values found! Filling with default values...")
    data = data.ffill()  # Forward fill for missing values

# Encoding categorical variables
label_encoder = LabelEncoder()
for column in ['Gender', 'Goal', 'Fitness Level', 'Equipment', 'Exercises', 'Intensity', 'Frequency']:
    data[column] = label_encoder.fit_transform(data[column])

# Features (X) and Target (y)
X = data[['Age', 'Gender', 'Weight', 'Goal', 'Fitness Level', 'Duration', 'Equipment', 'Intensity']]
y = data['Exercises']  # Predicting 'Exercises'

# Standardize numerical features
scaler = StandardScaler()
X.loc[:, ['Age', 'Weight', 'Duration']] = scaler.fit_transform(X[['Age', 'Weight', 'Duration']])

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the model
model = RandomForestClassifier(random_state=42, class_weight='balanced')  # Class weight for imbalance
model.fit(X_train, y_train)

# Evaluate the model
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# Save the model and scaler for Streamlit deployment
joblib.dump(model, 'workout_recommender_model.pkl')
joblib.dump(scaler, 'scaler.pkl')

print("Model and scaler saved successfully!")